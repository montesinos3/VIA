{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de bordes\n",
    "\n",
    "En esta clase vamos a explorar el concepto de **[gradiente](https://en.wikipedia.org/wiki/Gradient#Definition) de la imagen** y a experimentar con detectores simples de \"bordes\" (*edges*) y segmentos de recta. Es la base de métodos de descripción de imágenes más potentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import cv2               as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fig(w,h):\n",
    "    plt.figure(figsize=(w,h))\n",
    "\n",
    "def readrgb(file):\n",
    "    return cv.cvtColor( cv.imread(\"../images/\"+file), cv.COLOR_BGR2RGB) \n",
    "\n",
    "def rgb2gray(x):\n",
    "    return cv.cvtColor(x,cv.COLOR_RGB2GRAY)\n",
    "\n",
    "def gray2float(x):\n",
    "    return x.astype(float) #/ 255\n",
    "\n",
    "# para ver imágenes monocromas autoescalando el rango\n",
    "def imshowg(x):\n",
    "    plt.imshow(x, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiente de la imagen\n",
    "\n",
    "En cada pixel de la imagen vamos a definir un vector que indica la dirección hacia la que aumenta la intensidad de luz. Es el \"gradiente\" en ese punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cogemos cualquier imagen de prueba\n",
    "img = readrgb('cube3.png')\n",
    "g   = gray2float(rgb2gray(img))\n",
    "imshowg(g);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gradiente se calcula normalmente tras un suavizado, para obtener los cambios de intensidad a la escala de detalle deseada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = cv.GaussianBlur(g,(0,0),10)\n",
    "imshowg(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gradiente se puede representar con una imagen de 2 canales (HxWx2), donde cada posición `g[x,y]` es un vector, o con 2 arrays HxW con las componentes por separado. Usamos esta última forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x):\n",
    "    gx = cv.Sobel(x,-1,1,0)/8\n",
    "    gy = cv.Sobel(x,-1,0,1)/8\n",
    "    return gx,gy\n",
    "\n",
    "gx,gy = grad(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La máscara de [Sobel](https://en.wikipedia.org/wiki/Sobel_operator) produce un valor proporcional a la derivada. Dividimos por 8 para conseguir el valor real. Comprobamos el resultado que obtiene en una rampa horizontal de pendiente 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.outer(np.arange(10),[1,1,1,1,1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad(np.outer(np.arange(10),[1,1,1,1,1]).T.astype(np.uint8))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos por separado una imagen con todas las componentes $\\nabla_x$ y otra con todas las componentes $\\nabla_y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig(12,4)\n",
    "plt.subplot(1,2,1); imshowg(gx); plt.title('gx')\n",
    "plt.subplot(1,2,2); imshowg(gy); plt.title('gy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En gx las zonas blancas indican incremento de intensidad al movernos hacia la derecha, que es el sentido en que aumenta la coordenada \"columna\". En \"gy\" las zonas blancas indican incremento de intensidad al movernos hacia abajo, que es la dirección en la que aumenta la coordenada \"fila\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es más ilustrativo mostrar el gradiente como campo vectorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para generar un \"grid\" con coordenadas\n",
    "def dom(sz, by=1):\n",
    "    r,c = sz\n",
    "    x,y = np.meshgrid(range(0,c,by),range(0,r,by))\n",
    "    return x,y\n",
    "\n",
    "# saltamos de 10 en 10 para no poner demasiadas flechas en la imagen\n",
    "x,y = dom(s.shape,10)\n",
    "\n",
    "r1 = y\n",
    "c1 = x\n",
    "r2 = -gy[r1,c1]   # filas = - eje Y\n",
    "c2 =  gx[r1,c1]\n",
    "\n",
    "fig(12,8)\n",
    "imshowg(s)\n",
    "plt.quiver(c1, r1, c2, r2, color='red',width=0.001,headwidth=5);\n",
    "plt.title('gradiente');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las zonas uniformes tienen gradiente nulo, y en las zonas de pendiente pronunciada vemos que los vectores apuntan hacia las zonas más claras de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Gradiente en forma polar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frecuentemente es preferible expresar el gradiente en [coordenadas polares](https://en.wikipedia.org/wiki/Polar_coordinate_system) (módulo y ángulo). Además, el ángulo se suele discretizar en un pequeño número de orientaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bordes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos en detalle los pixels de la fila 200 de la imagen (estirados en vertical para verlos mejor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "franja = np.zeros([30,s.shape[1]]) + g[200]\n",
    "fig(10,4)\n",
    "\n",
    "imshowg(franja); plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La misma fila suavizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "franja = np.zeros([30,s.shape[1]]) + s[200]\n",
    "fig(10,4)\n",
    "\n",
    "imshowg(franja); plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos los perfiles de niveles de gris en esa fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig(10,4)\n",
    "plt.plot(g[200],label='original');\n",
    "plt.plot(s[200],label='suavizada');\n",
    "plt.title('fila 200')\n",
    "plt.xlabel('columna'); plt.ylabel('nivel de gris'); plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro problema es encontrar la posición precisa de los bordes teniendo en cuenta que el \"escalón\" de nivel de gris que observamos en la imagen puede ser bastante gradual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la derivada de la imagen suavizada en esa fila ($\\nabla_x$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig(10,4)\n",
    "plt.plot(s[200],label='suavizada');\n",
    "plt.plot(10*gx[200],label='derivada (10x)');\n",
    "plt.hlines([0],xmin=0,xmax=640,lw=0.1)\n",
    "plt.title('fila 200')\n",
    "plt.xlabel('columna'); plt.ylabel('nivel de gris'); plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los extremos de la derivada ocurren en los puntos de máxima pendiente de nivel de gris, que son la mejor estimación de la posición del borde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelextrema\n",
    "\n",
    "pix = gx[200]\n",
    "\n",
    "THG = 0.2\n",
    "edgesp = argrelextrema(pix*(pix> THG),np.greater,order=5)[0]\n",
    "edgesn = argrelextrema(pix*(pix<-THG),np.less,   order=5)[0]\n",
    "\n",
    "print(edgesp)\n",
    "print(edgesn)\n",
    "\n",
    "fig(10,4)\n",
    "plt.plot(s[200],label='suavizada');\n",
    "plt.plot(10*gx[200],label='derivada (10x)');\n",
    "plt.hlines([0],xmin=0,xmax=640,lw=0.1)\n",
    "plt.vlines(edgesp,ymin=0,ymax=200,colors='green',lw=0.5);\n",
    "plt.vlines(edgesn,ymin=0,ymax=200,colors='red',lw=0.5);\n",
    "plt.title('fila 200')\n",
    "plt.xlabel('columna'); plt.ylabel('nivel de gris'); plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "franja = np.zeros([30,s.shape[1]]) + s[200]\n",
    "fig(10,4)\n",
    "\n",
    "imshowg(franja); plt.axis('off');\n",
    "#imshowg(grad(franja)[0]); plt.axis('off');\n",
    "plt.vlines(edgesp,ymin=-10,ymax=40,colors='green',lw=0.5);\n",
    "plt.vlines(edgesn,ymin=-10,ymax=40,colors='red',lw=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no se suaviza la imagen, o el nivel de suavizado es muy pequeño (el operador de Sobel realiza implícitamente un suavizado leve), aparecen muchos más bordes debido al ruido de imagen o a detalles de tamaño pequeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig(10,4)\n",
    "plt.plot(g[200],label='original');\n",
    "plt.plot(grad(g)[0][200],label='derivada');\n",
    "plt.title('fila 200')\n",
    "plt.xlabel('columna'); plt.ylabel('nivel de gris'); plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pix = grad(g)[0][200]\n",
    "\n",
    "THG = 2\n",
    "edgesp = argrelextrema(pix*(pix> THG),np.greater,order=5)[0]\n",
    "edgesn = argrelextrema(pix*(pix<-THG),np.less,   order=5)[0]\n",
    "\n",
    "print(edgesp)\n",
    "print(edgesn)\n",
    "\n",
    "fig(10,4)\n",
    "plt.plot(g[200],label='original');\n",
    "plt.plot(pix,label='derivada');\n",
    "plt.hlines([0],xmin=0,xmax=640,lw=0.1)\n",
    "plt.vlines(edgesp,ymin=0,ymax=200,colors='green',lw=0.5);\n",
    "plt.vlines(edgesn,ymin=0,ymax=200,colors='red',lw=0.5);\n",
    "plt.title('fila 200')\n",
    "plt.xlabel('columna'); plt.ylabel('nivel de gris'); plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "franja = np.zeros([30,s.shape[1]]) + g[200]\n",
    "fig(10,4)\n",
    "\n",
    "imshowg(franja); plt.axis('off');\n",
    "#imshowg(grad(franja)[0]); plt.axis('off');\n",
    "plt.vlines(edgesp,ymin=-10,ymax=40,colors='green',lw=0.5);\n",
    "plt.vlines(edgesn,ymin=-10,ymax=40,colors='red',lw=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La detección de bordes siempre se hace sobre un determinado nivel de suavizado o escala de detalle $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la segunda derivada. Sus *cruces por cero* corresponden con los extremos de primera derivada y también indican la posición de los bordes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gxx,_ = grad(gx)\n",
    "\n",
    "fig(10,4)\n",
    "plt.plot(s[200],label='suavizada');\n",
    "plt.plot(20*gx[200],label='derivada (20x)');\n",
    "plt.plot(100*gxx[200],label='2ª derivada (100x)');\n",
    "plt.hlines([0],xmin=0,xmax=640,lw=0.1)\n",
    "plt.title('fila 200')\n",
    "plt.xlabel('columna'); plt.ylabel('nivel de gris'); plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la imagen es una función de dos variables tiene 4 derivadas segundas (las dos cruzadas coinciden)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx,gy = grad(cv.GaussianBlur(g,(0,0),4))\n",
    "\n",
    "gxx,gxy = grad(gx)\n",
    "gyx,gyy = grad(gy)\n",
    "\n",
    "fig(12,8)\n",
    "plt.subplot(2,2,1); imshowg(gxx); plt.title('gxx')\n",
    "plt.subplot(2,2,2); imshowg(gxy); plt.title('gxy')\n",
    "plt.subplot(2,2,3); imshowg(gyx); plt.title('gyx=gxy')\n",
    "plt.subplot(2,2,4); imshowg(gyy); plt.title('gyy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con ellas conseguimos dos operadores importantes: Laplaciano y Hessiano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = gxx+gyy\n",
    "H = gxx*gyy-gxy**2\n",
    "\n",
    "fig(12,4)\n",
    "plt.subplot(1,2,1); imshowg(L); plt.title('Laplaciano')\n",
    "plt.subplot(1,2,2); imshowg(H); plt.title('Hessiano');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos operadores se utilizarán más adelante para describir localmente la estructura de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operador de Marr–Hildreth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extendiendo el razonamiento anterior al caso de 2 dimensiones llegamos a un primer método de detección de bordes ([Marr-Hildreth](http://rspb.royalsocietypublishing.org/content/207/1167/187)). Se basa en encontrar los cruces por cero del Laplaciano de la imagen, previamente suavizada con un filtro gaussiano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import minimum_filter, maximum_filter\n",
    "\n",
    "mn = minimum_filter(L,3)\n",
    "mx = maximum_filter(L,3)\n",
    "z = mn*mx < 0\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(z);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las operaciones de suavizado gaussiano y Laplaciano se pueden realizar simultaneamente con el operador $LoG(\\sigma)$ que tiene forma de [sombrero mexicano](https://en.wikipedia.org/wiki/Mexican_hat_wavelet) invertido. Su efecto puede aproximarse bien mediante la diferencia de dos suavizados gaussianos ([DoG](https://en.wikipedia.org/wiki/Difference_of_Gaussians)), que normalmente se calculan eficientemente en una cascada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operador de Canny\n",
    "\n",
    "Es el [método estándar](https://en.wikipedia.org/wiki/Canny_edge_detector) de detección precisa de bordes. Busca los máximos locales del módulo del gradiente *en la dirección* del gradiente. Los bordes más intensos se seleccionan mediante un *umbralizado con histéresis* para conseguir secuencias continuas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv.Canny(cv.GaussianBlur(g,(0,0),2).astype(np.uint8),20,60)\n",
    "\n",
    "fig(12,8)\n",
    "plt.imshow(edges, 'gray', interpolation='bicubic');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los puntos de borde detectados se pueden extraer como secuencias de puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Ejercicio**: Escribe una implementación sencilla de la etapa de *supresión de no máximos* del método de Canny, preferiblemente usando operaciones vectorizadas de numpy. (Una solución posible se muestra en [cannyC.ipynb](cannyC.ipynb).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Información en los bordes\n",
    "\n",
    "Casi toda la información de la imagen está en los puntos de borde. El resto es uniforme y se podría deducir.\n",
    "\n",
    "Se puede reconstruir una versión aceptable de la imagen mediante \"[inpainting](ipmisc.ipynb)\" de los bordes de Canny. Los ensanchamos un poco con una [operación morfológica](http://docs.opencv.org/master/d9/d61/tutorial_py_morphological_ops.html#gsc.tab=0) de dilatación para que haya información de color más o menos definida a cada lado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker = np.ones((5,5),np.uint8)\n",
    "\n",
    "#mask = 255-edges\n",
    "mask = 255-cv.dilate(edges, ker)\n",
    "fig(12,8)\n",
    "imshowg(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = (255-mask).reshape(480,640,1).astype(bool)\n",
    "xx = np.zeros([480,640,3],dtype=np.uint8)\n",
    "np.copyto(xx, img, where = m3)\n",
    "\n",
    "dst = cv.inpaint(img,mask,3,cv.INPAINT_NS);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig(15,6)\n",
    "plt.subplot(1,2,1); plt.imshow(xx);\n",
    "plt.subplot(1,2,2); plt.imshow(dst);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentos de recta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunas aplicaciones necesitamos detectar bordes rectos. Una forma de conseguirlo es la [Transformada de Hough](https://en.wikipedia.org/wiki/Hough_transform). La idea es construir un espacio discretizado de los parámetros de todas las posibles rectas y cada punto de borde vota en todas las rectas que pasan por él.\n",
    "\n",
    "Partimos de los bordes de Canny (o de cualquier otro filtro de alta frecuencia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = readrgb('pano/pano000.jpg')\n",
    "g = cv.GaussianBlur(rgb2gray(img),(0,0),2)\n",
    "\n",
    "edges = cv.Canny(g,20,80)\n",
    "fig(12,8)\n",
    "imshowg(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos el resultado de la implementación disponible en scikit-image. (La versión de OpenCV es menos cómoda de utilizar.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import probabilistic_hough_line\n",
    "\n",
    "lines = probabilistic_hough_line(edges, \n",
    "                                 threshold=10, \n",
    "                                 line_length=20,\n",
    "                                 line_gap=3)\n",
    "fig(12,8)\n",
    "plt.imshow(img)\n",
    "ax = plt.axis()\n",
    "\n",
    "for line in lines:\n",
    "    p0, p1 = line\n",
    "    plt.plot((p0[0], p1[0]), (p0[1], p1[1]),'r')\n",
    "\n",
    "plt.axis(ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La técnica puede extenderse a estructuras geométricas más complejas como círculos, polígonos, etc. usando un espacio de parámetros de más dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograma de orientaciones de gradiente (HOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos visto que la distribución (histograma) de colores es una característica que permite distinguir algunos tipos de objetos, siempre que sean de colores muy distintos y las condiciones de iluminación no cambien mucho.\n",
    "\n",
    "De forma parecida, la distribución de los vectores de gradiente permite caracterizar el aspecto de objetos rígidos o que sufren deformaciones pequeñas. Para que esto sea efectivo es necesario calcular varios **histogramas locales** en una malla que cubre la región de interés (no un único histograma de toda ella).  Y, lo que es más importante, el histograma debe hacerse sobre las **orientaciones** del gradiente (ángulos discretizados). En cada celda se contabiliza la magnitud total de gradiente que hay en cada orientación.\n",
    "\n",
    "Esta operación se conoce como [HOG](https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients) ([Dalal & Triggs, 2005](https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf)) y es una de las técnicas clásicas más utilizadas para la detección de objetos semirígidos como  peatones, caras, vehículos, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a calcular manualmente un histograma de orientaciones de gradiente con operaciones de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rgb2gray(readrgb('madelman.png'))\n",
    "imshowg(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ampliamos mucho los pixels y mostramos el nivel de gris de cada uno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trozo = x[30:70, 50:80]\n",
    "h,w = trozo.shape\n",
    "fig(16,16)\n",
    "plt.imshow(trozo,'gray',vmin=0,vmax=255)\n",
    "for j in range(w):\n",
    "    plt.hlines(np.arange(h)-0.5,-0.5,w,lw=0.5)\n",
    "for i in range(h):\n",
    "    plt.vlines(np.arange(w)-0.5,-0.5,h,lw=0.5)\n",
    "    for j in range(w):\n",
    "        plt.text(j,i,'{:02x}'.format(trozo[i,j]),color='black' if trozo[i,j] > 128 else 'white',\n",
    "                 horizontalalignment='center',verticalalignment='center',fontsize=8);\n",
    "plt.xlim(-0.5,w-0.5); plt.ylim(h-0.5,-0.5);\n",
    "plt.title('niveles de gris (hex)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos el gradiente en un fragmento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trozo = x[35:55, 55:80]\n",
    "gx = cv.Sobel(trozo,cv.CV_16S,1,0) //8\n",
    "gy = cv.Sobel(trozo,cv.CV_16S,0,1) //8\n",
    "gm = np.sqrt(gx**2+gy**2).astype(int)\n",
    "ga = np.arctan2(gy,gx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dom(trozo.shape)\n",
    "\n",
    "r1 = y\n",
    "c1 = x\n",
    "r2 = -gy[r1,c1]   # filas = - eje Y\n",
    "c2 =  gx[r1,c1]\n",
    "\n",
    "fig(16,14)\n",
    "plt.imshow(trozo,'gray',vmin=0,vmax=255)\n",
    "#plt.imshow(gx,'coolwarm',vmin=-128,vmax=128)\n",
    "\n",
    "plt.quiver(c1, r1, c2, r2, color='orange', width=0.002, scale=50, scale_units='xy');\n",
    "\n",
    "h,w = trozo.shape\n",
    "if False:\n",
    "    for j in range(w):\n",
    "        plt.hlines(np.arange(h)-0.5,-0.5,w,lw=0.5)\n",
    "    for i in range(h):\n",
    "        plt.vlines(np.arange(w)-0.5,-0.5,h,lw=0.5)\n",
    "    \n",
    "plt.xlim(-0.5,w-0.5); plt.ylim(h-0.5,-0.5);\n",
    "plt.title('gradiente'); plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducimos el ángulo a 4 direcciones: 0-- 1/  2| 3\\ . (La forma hacerlo se explica en el notebook [cannyC](cannyC.ipynb).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "gad = (np.round(ga / np.pi * 4) % 4).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos en cada píxel la magitud del gradiente precedido del código de orientación (solo donde el gradiente es aprecible):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "fig(16,14)\n",
    "plt.imshow(trozo,'gray',vmin=0,vmax=255)\n",
    "#plt.imshow(gx,'coolwarm',vmin=-128,vmax=128)\n",
    "h,w = trozo.shape\n",
    "for j in range(w):\n",
    "    plt.hlines(np.arange(h)-0.5,-0.5,w,lw=0.5)\n",
    "for i in range(h):\n",
    "    plt.vlines(np.arange(w)-0.5,-0.5,h,lw=0.5)\n",
    "    for j in range(w):\n",
    "        if gm[i,j]> 15:\n",
    "            plt.text(j,i,'{}-{}'.format(gad[i,j], gm[i,j]),color='black' if trozo[i,j] > 128 else 'white',\n",
    "                     horizontalalignment='center',verticalalignment='center',fontsize=8);\n",
    "plt.xlim(-0.5,w-0.5); plt.ylim(h-0.5,-0.5);\n",
    "plt.title('gradiente: código ángulo - magnitud');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es mejor visualizar la esta información con líneas que indican la intensidad de borde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "dx = np.cos(np.radians([90,135,0,45]))\n",
    "dy = np.sin(np.radians([90,135,0,45]))\n",
    "\n",
    "def edge(x,y,g,a):\n",
    "    plt.plot([x-g*dx[a],x+g*dx[a]],[y-g*dy[a],y+g*dy[a]],color='black')\n",
    "\n",
    "\n",
    "fig(16,14)\n",
    "plt.imshow(255-trozo*0,'gray',vmin=0,vmax=255)\n",
    "#plt.imshow(gx,'coolwarm',vmin=-128,vmax=128)\n",
    "h,w = trozo.shape\n",
    "for j in range(w):\n",
    "    plt.hlines(np.arange(h)-0.5,-0.5,w,lw=0.5,color='lightgray')\n",
    "for i in range(h):\n",
    "    plt.vlines(np.arange(w)-0.5,-0.5,h,lw=0.5,color='lightgray')\n",
    "    for j in range(w):\n",
    "        edge(j,i,gm[i,j]/100,gad[i,j])\n",
    "plt.xlim(-0.5,w-0.5); plt.ylim(h-0.5,-0.5);\n",
    "plt.title('intensidad de borde'); #plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el histograma de esas cuatro direcciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(gad,bins=[0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es lo mismo que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.sum(gad==x) for x in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero lo que realmente nos interesa es contabilizar la cantidad total de intensidad en cada orientación (no el mismo valor de 1 en cada pixel, independientemente de la intensidad del gradiente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.sum(gm[gad==x]) for x in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta operación es un histograma con pesos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(gad, weights=gm, bins=[0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es preferible normalizar el histograma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.histogram(gad, bins=[0,1,2,3,4], weights=gm, density=True)[0]\n",
    "feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta región la dirección 2 es la más frecuente (gradiente vertical, borde horizontal), seguida de la 0 y la 1. Hay muy pocas orientaciones tipo 3. El histograma se puede representar gráficamente así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig(4,4)\n",
    "ax = plt.axis([-0.5,0.5,0.5,-0.5]);\n",
    "for v,c in zip(feature, range(4)):\n",
    "    edge(0,0,v,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las imágenes se particionan en celdas (de tamaño 16x16, por ejemplo) y en cada una de ellas se calcula el histograma de orientaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la práctica es conveniente agrupar las celdas en bloques (de tamaño 2x2, por ejemplo) para normalizar los histogramas de cada celda teniendo en cuenta un contexto más amplio. Los bloques están solapados y por tanto cada celda contribuye a varios bloques con diferente normalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG en OpenCV y scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos calcular los histogramas de orientaciones de gradiente con OpenCV, pero scikit-image proporciona también una representación visual de los histogramas muy informativa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "x = rgb2gray(readrgb('madelman.png'))\n",
    "\n",
    "v,sh = hog(x, orientations=8, pixels_per_cell=(8,8), cells_per_block=(2,2),\n",
    "              visualize=True, transform_sqrt=True, feature_vector=False, block_norm='L2-Hys')\n",
    "\n",
    "print(x.shape, v.shape)\n",
    "\n",
    "fig(12,8)\n",
    "imshowg(255-sh);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para intentar encontrar este objeto en otra imagen calculamos este tipo de histograma de bordes sobre la imagen completa y comparamos con el HOG del modelo en todas las posiciones mediante una \"sliding window\". La detección del objeto de cualquier tamaño se hace repitiendo el proceso sobre una \"pirámide\" de escalas (una secuencia de imágenes progresivamente más pequeñas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "En el laboratorio implementaremos una versión básica de esta idea comparando los HOG mediante una distancia simple ([`hog0.py`](../code/hog/hog0.py)). Para conseguir resultados más precisos hay que recurrir a técnicas de *machine learning* más potentes.\n",
    "El ejemplo de código [`pedestrian.py`](../code/hog/pedestrian.py)  muestra cómo utilizar un clasificador de personas preentrenado que incluye OpenCV, basado en HOG y [SVM](https://en.wikipedia.org/wiki/Support_vector_machine) ([blog post](http://www.pyimagesearch.com/2015/11/09/pedestrian-detection-opencv/)).\n",
    "\n",
    "El ejemplo [`facelandmarks.py`](../code/hog/facelandmarks.py) muestra el funcionamiento del detector de caras basado en HOG disponible en la biblioteca [dlib](http://dlib.net/), que también incluye un detector de marcadores faciales.\n",
    "\n",
    "Esta biblioteca incluye también una herramienta para etiquetar ejemplos en imágenes de entrenamiento y validación, y código para entrenar un clasificador."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

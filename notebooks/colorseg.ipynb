{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentación por color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos de una imagen que tiene varias zonas de interés, en este caso \"vegetación\" y \"tierra\", y tratamos de distinguirlas usando un modelo de color sencillo. (El código siguiente funcionará igual si hay más de dos clases.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import cv2               as cv\n",
    "import skimage           as si\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "from matplotlib.pyplot import imshow, subplot, title\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig(w,h):\n",
    "    return plt.figure(figsize=(w,h))\n",
    "\n",
    "def readrgb(file):\n",
    "    return cv.cvtColor( cv.imread(\"../images/\"+file), cv.COLOR_BGR2RGB) \n",
    "\n",
    "def rgb2yuv(x):\n",
    "    return cv.cvtColor(x,cv.COLOR_RGB2YUV)\n",
    "\n",
    "def yuv2rgb(x):\n",
    "    return cv.cvtColor(x,cv.COLOR_YUV2RGB)\n",
    "\n",
    "byte = np.uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = readrgb(\"d1.jpg\")\n",
    "imshow(img); title('original');\n",
    "rows,cols,d = img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recortamos un trozo de cada región."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = img[200:400,300:500]\n",
    "r2 = img[200:400,2100:2300]\n",
    "models = [r1,r2]\n",
    "\n",
    "imshow(np.hstack(models)); title('muestras de cada tipo');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo muy simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una primera idea sería calcular el color \"típico\" (medio) de cada región y clasificar los pixels por mínima distancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = [ np.mean(r,(0,1)) for r in models ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos unos cuadritos del color medio de cada región\n",
    "\n",
    "muestras = []\n",
    "for color in med:\n",
    "    x = np.zeros([100,100,3],byte)\n",
    "    x[:,:] = color\n",
    "    muestras.append(x)\n",
    "\n",
    "imshow(np.hstack(muestras));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos las diferencias absolutas de los pixels RGB y cada color medio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [ np.sum(abs(img - m), axis=2) for m in med ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada pixel calculamos en qué modelo se obtiene el valor mínimo de distancia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c  = np.argmin(d, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta imagen de etiquetas se puede mostrar ya directamente. Matplotlib autoescala los valores 0,1,... encontrados y los reparte entre negro y blanco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(c,'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero es mejor representar cada pixel con el color medio de la categoría asignada. Para ello, preparamos una imagen para contener el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros(img.shape, byte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la rellenamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(models)):\n",
    "    res[c==k] = med[k]\n",
    "\n",
    "imshow(res);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este resultado se han clasificado todos los pixels, lo que no tiene mucho sentido. Deberíamos eliminar los que no pertenecen a ningún modelo (aquellos cuya distancia mínima sea grande) y los dudosos (los que están a una distancia parecida de varios modelos). Esto lo haremos correctamente más adelante. Por ahora simplemente eliminamos los que tienen una distancia menor \"grande\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = np.min(d, axis=0)\n",
    "\n",
    "res [md > 40] = 0,0,0\n",
    "\n",
    "imshow(res);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No está mal, pero no está claro cuál es el umbral de distancia más adecuado.\n",
    "\n",
    "Vamos a intentar construir un modelo de color que tenga en cuenta los matices de color de cada región y usaremos un método de clasificación más preciso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación probabilística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro objetivo es clasificar los pixels de la imagen de acuerdo con la clase más probable. Las clases son las distintas distribuciones de color extraídas de las regiones seleccionadas. Para ello necesitamos una estimación de la probabilidad de que un pixel sea de la clase $C$ si tiene color $p$ (sus valores RGB, ó UV, etc.):\n",
    "\n",
    "$$\\mathcal P(C \\mid p)$$\n",
    "\n",
    "Esto se puede calcular así (regla de Bayes):\n",
    "\n",
    "$$\\mathcal P(C \\mid p) = \\frac{\\mathcal P(p \\mid C)\\; \\mathcal P(C)}{ \\mathcal P(p)} $$\n",
    "\n",
    "$ \\mathcal P(C) $ es la probabilidad *a priori* de la clase $C$. Si no se dice otra cosa, podemos suponer que todas las clases son igualmente probables.\n",
    "\n",
    "\n",
    "El denominador es la probabilidad de observar ese pixel en cualquiera de las clases. Se calcula como la suma de todos los numeradores.\n",
    "\n",
    "$$\\mathcal P(p) = \\sum_C \\mathcal P(p \\mid C) \\; \\mathcal P(C)$$\n",
    "\n",
    "(Si es cero o muy pequeño nos indica que no podemos clasificar el pixel $p$, porque su color no se ha visto en ninguno de los modelos que estamos considerando.)\n",
    "\n",
    "Por tanto, la clave está en conseguir una estimación de los términos $\\mathcal P(p \\mid C)$, la probabilidad de observar el color $p$ en cada cada clase C. Es el *modelo de medida*. Nos da la distribución de colores en cada clase.\n",
    "\n",
    "La forma más sencilla de estimar este modelo es usar un *histograma*, que nos da las frecuencias de cada color en un espacio discretizado, y que podemos suponer parecidas a la probabilidad real. (Los histogramas solo son prácticos en espacios de dimensión muy pequeña, ya que el número de \"cajas\" crece exponencialmente.)\n",
    "\n",
    "En la práctica, dado un pixel $p$ que queremos clasificar, lo único que debemos hacer es preguntarle a los histogramas de cada clase la frecuencia con que se observó $p$ y elegir la clase que tenga mayor valor. (Si las probabilidades \"a priori\" son distintas hay que multiplicar por ellas).\n",
    "\n",
    "Simplemente hay que tener en cuenta que debemos rechazar la clasificación de los pixels que tengan un valor muy pequeño de $\\mathcal P(p)$, y que dividiendo por este valor conseguimos las probabilidades de cada clase.\n",
    "\n",
    "Estas operaciones se pueden hacer de manera muy simple utilizando numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo vamos a modelar la distribución de colores de las clases mediante histogramas de los valores conjuntos de los canales UV del espacio YUV. La idea es quitar la componente de luminosidad y quedarnos solo con la información de color, para que las sombras o la cantidad total de luz no influyan. (Esto no funcionará bien para distinguir zonas con tonos de blanco, negro o gris.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcula el histograma (normalizado) de los canales conjuntos UV\n",
    "def uvh(x):\n",
    "\n",
    "    # normalizar un histograma\n",
    "    # para tener frecuencias (suman 1)\n",
    "    # en vez de número de elementos\n",
    "    def normhist(x): return x / np.sum(x)\n",
    "\n",
    "    yuv = rgb2yuv(x)\n",
    "    h = cv.calcHist([yuv]     # necesario ponerlo en una lista aunque solo admite un elemento\n",
    "                    ,[1,2]    # elegimos los canales U y V\n",
    "                    ,None     # posible máscara\n",
    "                    ,[32,32]  # las cajitas en cada dimensión\n",
    "                    ,[0,256]+[0,256] # rango de interés (todo)\n",
    "                   )\n",
    "    return normhist(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta función obtenemos los modelos de color de todas las regiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = [uvh(r) for r in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El significado del histograma 2D es el siguiente. Por ejemplo, el valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist[0][15,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "significa que en la región \"vegetación\" la frecuencia con la que han aparecido colores que tienen un valor de U entre $14 \\times 8$ y $15 \\times 8$ y a la vez un valor de V entre $9 \\times 8$ y $10 \\times 8$ es del 21%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el histograma es 2D, podemos mostrarlo con barras verticales que indican la frecuencia de cada \"caja de color\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fg = plt.figure(figsize=(14, 6))\n",
    "\n",
    "_xx, _yy = np.meshgrid(np.arange(32), np.arange(32))\n",
    "x, y = _xx.ravel(), _yy.ravel()\n",
    "bottom = 0\n",
    "width = depth = 1\n",
    "\n",
    "ax1 = fg.add_subplot(121, projection='3d')\n",
    "top = hist[0].ravel()\n",
    "ax1.bar3d(x, y, bottom, width, depth, top , shade=True);\n",
    "\n",
    "ax1 = fg.add_subplot(122, projection='3d')\n",
    "top = hist[1].ravel()\n",
    "ax1.bar3d(x, y, bottom, width, depth, top, shade=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra posibilidad es mostrarlos como imágenes, transformando a escala logarítmica para que no solo se vean bien los picos más altos.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.set_cmap('gray')\n",
    "plt.imshow(np.hstack([np.log(1+h) for h in hist]),vmax=1E-3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos añadir el el color típico de cada celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv = np.zeros([32,32,3],dtype=np.uint8)\n",
    "ran = np.linspace(0,256-8,32)+4\n",
    "(v,u) = np.meshgrid(ran,ran)\n",
    "\n",
    "uv[:,:,0] = 128\n",
    "uv[:,:,1] = u\n",
    "uv[:,:,2] = v\n",
    "\n",
    "plt.imshow(yuv2rgb(uv)); plt.xlabel('V'); plt.ylabel('U'); plt.title('espacio UV para Y=128');\n",
    "# consistente con la matriz de histograma, no con valores reales de UV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vhist = [ yuv2rgb(uv) * (h > 0).reshape(32,32,1) for h in hist]\n",
    "\n",
    "fig(8,4)\n",
    "subplot(1,2,1); imshow(vhist[0]);\n",
    "subplot(1,2,2); imshow(vhist[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí vemos los dos histogramas juntos, donde se observa que los colores de las regiones seleccionadas están bien separados (aunque no muy alejados) en el espacio UV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(np.maximum(np.log(1+hist[0]),np.log(1+hist[1])),vmax=1E-3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En  este ejemplo las distribuciones de las dos clases son bastante compactas, lo que significa que el valor medio podría ser suficiente. (Los modelos de histograma tienen ventajas cuando las distribuciones son más complejas.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora convertimos al espacio UV la imagen completa que queremos \"segmentar\" (clasificar). Tenemos que dividir por 8 (cociente de la división entera) para obtener los índices correctos de la caja del histograma. Recordad que usamos 32 divisiones en cada dimensión. (Estamos despreciando los 3 bits menos significativos del los valores de U y V)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canales UY reducidos a una resolución de 5 bits (32 niveles)\n",
    "uvr = np.floor_divide( cv.cvtColor(img,cv.COLOR_RGB2YUV)[:,:,[1,2]], 8)\n",
    "print(uvr.shape, uvr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(uvr[:,:,1]); title('canal V');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya solo tenemos que consultar, para cada pixel de la imagen, los histogramas de cada región, que nos dirán la \"verosimilitud\" de cada clase en ese punto. Para ello aprovechamos la potencia expresiva de numpy, indexando los histogramas con toda la imagen. (Esta operación puede hacerse también usando la función de opencv [histogram backprojection](http://docs.opencv.org/3.1.0/dc/df6/tutorial_py_histogram_backprojection.html).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = uvr[:,:,0]\n",
    "v = uvr[:,:,1]\n",
    "\n",
    "lik = [ h[u,v] for h in hist ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos para cada clase, una imagen float que nos indica en cada punto lo verosímil que es. Opcionalmente podemos suavizarla un poco para hacer que los pixels vecinos influyan un poco en los casos dudosos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lik = [ cv.GaussianBlur(l, (0,0), 10) for l in lik ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(lik[0], 'gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(lik[1], 'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora necesitamos el denominador $\\mathcal P(p)$, o \"evidencia\" de cada punto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.sum(lik, axis=0)\n",
    "\n",
    "imshow(E,'gray'); plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que nos permite normalizar las verosimilitudes y conseguir probabilidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array(lik) / E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se produce un warning debido a las divisiones por cero, en los pixels de un color que no se ha visto nunca, desconocido para el modelo. (No nos preocupa porque luego vamos a eliminar los puntos problemáticos.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las probabilidades se han guardado en un array 3D. La clasificación se realiza obteniendo en cada punto la clase que tiene mayor probabilidad, lo que se puede conseguir directamente con la función `np.argmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c  = np.argmax(p,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También necesitamos el valor de la probabilidad ganadora en cada punto (eliminando las divisiones por cero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = np.max(p, axis=0)\n",
    "mp[E < 0.1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mostrar el resultado rellenamos una imagen con el color medio de la clase ganadora en cada punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros(img.shape,np.uint8)\n",
    "for k in range(len(models)):\n",
    "    res[c==k] = med[k]\n",
    "\n",
    "imshow(res);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marcamos los puntos de baja evidencia (negro) y los que no tengan una probabilidad suficienmente alta (rojo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[mp < 0.99] = 128,0,0\n",
    "res[E < 0.05] = 0,0,0\n",
    "imshow(res);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede obtener una máscara de, p. ej., los píxels de vegetación, lo que permitiría calcular su área o cualquier otra característica de interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow((c == 0) * (E>0.05) * (mp > 0.99)) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow( np.expand_dims( (c == 0) * (E>0.05) * (mp > 0.99) , axis=2) * img );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada pixel se ha clasificado de forma independiente, pero realmente habría que tener en cuenta de alguna manera un cierto entorno de cada pixel para tomar una decisión que fuera localmente coherente, produciendo regiones \"compactas\". Lo hemos hecho mediante el suavizado gaussiano anterior, pero hay formas mejores de hacerlo.\n",
    "\n",
    "El algoritmo [GrabCut](http://docs.opencv.org/3.2.0/d8/d83/tutorial_py_grabcut.html) optimiza una función objetivo que contiene un término de fidelidad al modelo de color, lo mismo que hemos tenido en cuenta en este ejemplo (aunque usa un modelo de mezcla de gaussianas en vez de un histograma), y otro término que produce un coste en todas las parejas de pixels vecinos que se etiquetan de forma distinta. Lo interesante es que la solución óptima de este problema puede conseguirse de forma eficiente mediante un algoritmo de cortes de grafos ([*graph cuts*](https://en.wikipedia.org/wiki/Graph_cuts_in_computer_vision)).\n",
    "\n",
    "El ejemplo de código `grabcut.py` es una demo interactiva de este método disponible en OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que queremos detectar la posicion de un objeto en movimiento en una secuencia de imágenes. Si el objeto es más o menos compacto y tiene un color característico podemos aplicar una técnica similar. A partir de la imagen de verosimilitud del modelo (la reproyección del histograma), podemos obtener la elipse de incertidumbre que engloba la mayor parte del objeto y con ella definir una región de interés del tamaño adecuado para trabajar en el frame siguiente.\n",
    "\n",
    "Esto es la base de las técnicas [*mean shift* y *cam shift*](http://docs.opencv.org/trunk/db/df8/tutorial_py_meanshift.html). Una demostración de esta técnica se muestra en el ejemplo de código `camshift.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otro ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = readrgb(\"falta2.jpg\")\n",
    "imshow(img); title('original');\n",
    "rows,cols,d = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = img[0:200,0:1000]\n",
    "r2 = img[800:1000,250:1750]\n",
    "models = [r1,r2]\n",
    "\n",
    "plt.figure(figsize=(12,2))\n",
    "plt.subplot(1,2,1); plt.imshow(r1)\n",
    "plt.subplot(1,2,2); plt.imshow(r2)\n",
    "plt.suptitle('muestras de cada tipo');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = [uvh(r) for r in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fg = plt.figure(figsize=(14, 6))\n",
    "\n",
    "_xx, _yy = np.meshgrid(np.arange(32), np.arange(32))\n",
    "x, y = _xx.ravel(), _yy.ravel()\n",
    "bottom = 0\n",
    "width = depth = 1\n",
    "\n",
    "ax1 = fg.add_subplot(121, projection='3d')\n",
    "top = hist[0].ravel()\n",
    "ax1.bar3d(x, y, bottom, width, depth, top , shade=True);\n",
    "\n",
    "ax1 = fg.add_subplot(122, projection='3d')\n",
    "top = hist[1].ravel()\n",
    "ax1.bar3d(x, y, bottom, width, depth, top, shade=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vhist = [ yuv2rgb(uv) * (h > 0).reshape(32,32,1) for h in hist]\n",
    "\n",
    "fig(8,4)\n",
    "subplot(1,2,1); imshow(vhist[0]);\n",
    "subplot(1,2,2); imshow(vhist[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uvr = np.floor_divide( cv.cvtColor(img,cv.COLOR_RGB2YUV)[:,:,[1,2]], 8)\n",
    "\n",
    "u = uvr[:,:,0]\n",
    "v = uvr[:,:,1]\n",
    "\n",
    "lik = [ h[u,v] for h in hist ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lik = [ cv.GaussianBlur(l, (0,0), 10) for l in lik ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(lik[0], 'gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(lik[1], 'gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.sum(lik, axis=0)\n",
    "p = np.array(lik) / E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c  = np.argmax(p,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = np.max(p, axis=0)\n",
    "mp[E < 0.01] = 0\n",
    "\n",
    "res = np.zeros(img.shape,np.uint8)\n",
    "\n",
    "med = [ np.mean(r,(0,1)) for r in models ]\n",
    "\n",
    "for k in range(len(models)):\n",
    "    res[c==k] = med[k]\n",
    "\n",
    "res[mp < 0.8] = 128,0,0\n",
    "res[E < 0.01] = 0,0,0\n",
    "imshow(res);"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformada de distancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[wikipedia](https://en.wikipedia.org/wiki/Distance_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchas tareas de procesamiento de imagen pueden atacarse de forma sencilla si se conoce la distancia de cualquier pixel de la imagen al punto más próximo de una determinada región $R$. En principio esto parece computacionalmente muy costoso, ya que exige calcular $N\\times M$ distancias, siendo $N$ el número de pixels de interés en la imagen y $M$ el de los que pertenecen a $R$. Si nos interesa la imagen completa este número es enorme. Afortunadamente, existen [algoritmos](https://www.springer.com/cda/content/document/cda_downloaddocument/9780387312019-c1.pdf) muy eficientes para calcular la distancia de todos los puntos de la imagen. Por ejemplo, es posible calcular la transformada de distancia euclídea (aproximada) mediante solo dos pasadas por la imagen ([Borgefors](https://www.realestatetrading.com/storage/documents/Borgefors86__Work.pdf))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy             as np\n",
    "import cv2               as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un ejemplo con la implementación de la transformada de distancia Euclídea exacta proporcionada por scipy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una imagen  de prueba con tres \"objetos\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "x = np.zeros([300,300])\n",
    "x[100:105,100:105] = 1\n",
    "x[200:250,200:205] = 2\n",
    "x[200:205,50:55] = 3\n",
    "\n",
    "plt.imshow(x,interpolation=None);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El convenio de esta función es que la región \"objeto\" $R$ tiene valor *False* (o cero). En ellos la distancia será cero. La función calcula la distancia en los pixels *True* (o mayores que cero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = distance_transform_edt(x==0)\n",
    "\n",
    "plt.imshow(d, 'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de la distancia, podemos pedir el pixel concreto más cercano. Esto nos permite segmentar la imagen en regiones de mayor proximidad. El truco para conseguir la representacion siguiente es marcar cada región con un número distinto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d,idxs = distance_transform_edt(x==0,return_indices=True)\n",
    "idxs.shape\n",
    "\n",
    "plt.imshow(x[idxs[0],idxs[1]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esqueleto de una figura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a aplicar la transformada para calcular la distancia desde dentro de una región hasta el exterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('../images/contours.png')\n",
    "g   = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "x = (g < 128)[10:350, 10:450]\n",
    "\n",
    "plt.imshow(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = distance_transform_edt(x)\n",
    "\n",
    "plt.imshow(d, 'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ampliamos un poco, y vemos como las zonas de máxima distancia se encuentran en la zona central de cada trozo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(d[200:310,120:250], 'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El [skeleton](http://scikit-image.org/docs/0.10.x/auto_examples/plot_medial_transform.html) de la figura es el conjunto de puntos que tienen al menos dos puntos frontera a la máxima distancia. Está implementado en *skimage*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import medial_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(medial_axis(x.astype(np.uint8)),interpolation='nearest');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación de estructuras convexas solapadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente imagen procede de una segmentación por color de una escena en la que hay numerosos objetos redondeados. Si estuvieran perfectamente separados se podrían identificar fácilmente mediante un sencillo etiquetado de componentes conexas. Al estar muchos de ellos pegados esto no funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('../images/segm.png')\n",
    "bw = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(bw,'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este tipo de problema la transformada de distancia es muy útil. En este ejemplo usamos la implementación de OpenCV, que nos pide el tipo de distancia y el tamaño de una máscara auxiliar. La image de entrada debe ser de tipo *byte*, y de nuevo los puntos del fondo, con valor cero, son la región respecto a la cual se calcula la distancia. Mostramos un fragmento ampliado del resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "td = cv.distanceTransform( (bw > 32).astype(np.uint8) , cv.DIST_L2, 5)\n",
    "plt.imshow(td[:200,:200],'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que los máximos de distancia están cerca del centro de cada mancha aunque haya objetos solapados: los estrechamientos producen picos de distancia claramente distintos. Estos picos pueden detectarse con una operación de \"supresión de no máximos\" (*nonmaxima supression (nms)*), que sea capaz de detectar máximos locales. Una forma simple de implementar esta operación consiste en comparar la imagen con un filtro de máximo de ella misma. Los máximos locales tendrán un valor igual al del máximo de sus vecinos. (Este método no es perfecto porque no tiene en cuenta posibles empates.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(x, t = 0.1):\n",
    "    m = cv.dilate(x, np.ones((5,5),np.uint8))  # filtro de máximo implementado como dilatación\n",
    "    h = np.max(m)\n",
    "    return (x == m) & (x > t*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una idea que parece funcionar bastante bien consiste en suavizar ligeramente la imagen de entrada (con la idea de redondear los bordes), binarizar con un umbral razonable para crear la imagen de entrada, y calcular un suavizado final de la transformada de distancia para deshacer posibles empates, dejando pixels individuales como centros de los objetos detectados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = 1\n",
    "H  = 32 \n",
    "S2 = 1\n",
    "\n",
    "dist = cv.GaussianBlur(cv.distanceTransform((cv.GaussianBlur(bw,(0,0),S1) > H).astype(np.uint8), cv.DIST_L2, 3),(0,0),S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(dist[:200,:200],'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos los máximos locales con nms, que produce una imagen booleana, y de ella extraemos las coordenadas de los extremos. El tamaño del cada objeto nos lo da precisamente el valor de la transformada de distancia en los extremos. Correspondería al radio si el objeto fuera perfectamente circular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = nms(dist)\n",
    "\n",
    "py,px = np.where(points)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "ax.imshow(dist); \n",
    "#ax.imshow(img,'gray')\n",
    "\n",
    "ax.plot(px,py,'.',color='red');\n",
    "\n",
    "for x,y in zip(px,py):\n",
    "    ax.add_patch(plt.Circle((x,y),dist[y,x],color='red',fill=False,lw=2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[watershed]: https://en.wikipedia.org/wiki/Watershed_(image_processing)\n",
    "\n",
    "Finalmente podemos comparar esta segmentación circular con el resultado obtenido por la técnica [watershed][watershed], que parte de \"semillas\" (en nuestro caso usamos los extremos de distancia) y va extendiendo las regiones hasta que se toquen, creando algo análogo a las cuencas hidrográficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,14))\n",
    "ws = cv.watershed(img,cv.connectedComponents(points.astype(np.uint8))[-1])\n",
    "plt.imshow(ws==-1,'gray');\n",
    "plt.plot(px,py,'.',color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hausdorff distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signed distance transform"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

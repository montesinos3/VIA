{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios propuestos en cursos anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Preguntas frecuentes](FAQ.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obligatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HANDS**: Amplia el ejemplo `code/DL/hands/mano.py` hecho en clase para reconocer gestos simples, como por ejemplo contar el número de dedos extendidos. Haz un controlador sin contacto de varios grados de libertad que mida, al menos, distancia de la mano a la cámara y ángulo de orientación. Utilízalo para controlar alguno de tus programas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FILTROS**. Muestra en vivo el efecto de diferentes filtros, seleccionando con el teclado el filtro deseado y modificando sus parámetros (p.ej. el nivel de suavizado) con trackbars. Aplica el filtro en un ROI para comparar el resultado con el resto de la imagen ([ejemplo](../images/demos/ej-c4.png))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLASIFICADOR**. Prepara una aplicación sencilla de reconocimiento de imágenes. Debe admitir (al menos) dos argumentos:\n",
    "\n",
    "`--models=<directorio>`, la carpeta donde hemos guardado un conjunto de imágenes de objetos o escenas que queremos reconocer.\n",
    "\n",
    "`--method=<nombre>`, el nombre de un método de comparación. \n",
    "\n",
    "Cada fotograma de entrada se compara con los modelos utilizando el método seleccionado y se muestra información sobre el resultado (el modelo más parecido o probable, las distancias a los diferentes modelos, alguna medida de confianza, etc.). Implementa inicialmente un método basado en el \"embedding\" obtenido por [mediapipe](https://developers.google.com/mediapipe/solutions/vision/image_embedder) (`code/DL/embbeder`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT**. Añade al ejercicio CLASIFICADOR un método basado en el número de coincidencias de *keypoints* SIFT. Utilízalo para reconocer objetos con bastante textura (p. ej. carátulas de CD, portadas de libros, cuadros de pintores, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECTIF**. Rectifica la imagen de un plano para medir distancias (tomando manualmente referencias conocidas). Por ejemplo, mide la distancia entre las monedas en `coins.png` o la distancia a la que se realiza el disparo en `gol-eder.png`. Las coordenadas reales de los puntos de referencia y sus posiciones en la imagen deben pasarse como parámetro en un archivo de texto. Aunque puedes mostrar la imagen rectificada para comprobar las operaciones, debes marcar los puntos y mostrar el resultado sobre la imagen original. Verifica los resultados con **imágenes originales** tomadas por ti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RA**. Crea un efecto de realidad aumentada en el que el usuario desplace objetos virtuales hacia posiciones marcadas con el ratón."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opcionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAPA**: Amplia el ejemplo `code/medidor.py` para convertir la distancia entre dos pixels marcados con el ratón en el ángulo que forman los rayos ópticos correspondientes, sabiendo el campo visual (FOV) de la cámara. Utiliza el script para encontrar mediante una construcción geométrica la posición aproximada en un mapa desde la que se ha tomado una imagen en la que se ven algunos puntos característicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FILTROS II**: **a)** Comprueba la propiedad de \"cascading\" del filtro gaussiano. **b)** Comprueba la propiedad de \"separabilidad\" del filtro gaussiano. **c)** Implementa en Python dede cero (usando bucles) el algoritmo de convolución con una máscara general y compara su eficiencia con la versión de OpenCV. **c)** Impleméntalo en C y haz un \"wrapper\" para utilizarlo desde Python (consulta al profesor). **d)** Implementa el box filter con la imagen integral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POLYGON**: Implementa un procedimiento para mejorar la aproximación poligonal obtenida por el método `cv.approxPolyDP` permitiendo vértices fuera del contorno de entrada. Da una medida de la calidad de la aproximación. Pruébalo construyendo un cuadrilátero a partir de la silueta de un carnet o una tarjeta con las esquinas redondeadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VROT**. Amplía el *tracker* de Lucas-Kanade (ejemplo `LK/lk_track.py`) para **a)** determinar en qué dirección se mueve la cámara (UP, DOWN, LEFT, RIGHT, FORWARD, BACKWARD); **b)** estimar de forma aproximada la velocidad angular de rotación de la cámara (grados/segundo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DL**. Entrena un modelo de deep learning con tus propias imágenes. Puedes utilizar la herramienta ultralytics, siguiendo [este ejemplo](https://docs.ultralytics.com/modes/train/#usage-examples), o el modelo propuesto en `code/DL/UNET`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUDOKU**. Haz un programa capaz de rellenar con realidad aumentada un sudoku que se observa en una imagen en vivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARD**. Sustituye la foto de tu carnet de la UMU que se observa en una imagen en vivo. Intenta conseguir un resultado parecido a `../images/demos/dni.mp4`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PANO**. Crea automáticamente un mosaico a partir de las imágenes en una carpeta. Las imágenes no tienen por qué estar ordenadas ni formar una cadena lineal y no sabemos el espacio que ocupa el resultado. El usuario debe intervenir lo menos posible. Recuerda que debe tratarse de una escena plana o de una escena cualquiera vista desde el mismo centro de proyección. Debes usar homografías. Compara el resultado con el que obtiene la utilidad de stitching de OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL3D**. Utiliza alguna de las herramientas [colmap](https://colmap.github.io/) o [meshroom](https://meshroom-manual.readthedocs.io/en/latest/) para construir un modelo 3D de un objeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LIBRE**. Resuelve un problema de visión artificial de tu elección. Solo se valorarán las aportaciones originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obligatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CALIBRACIÓN**. a) Realiza una calibración precisa de tu cámara mediante múltiples imágenes de un *chessboard*. b) Haz una calibración aproximada con un objeto de tamaño conocido y compara con el resultado anterior. c) Determina a qué altura hay que poner la cámara para obtener una vista cenital completa de un campo de baloncesto. d) Haz una aplicación para medir el ángulo que definen dos puntos marcados con el ratón en la imagen. e) Opcional: determina la posición aproximada desde la que se ha tomado una foto a partir ángulos observados respecto a puntos de referencia conocidos. [Más informacion](imagen.ipynb#Calibración)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ACTIVIDAD**. Construye un detector de movimiento en una región de interés de la imagen marcada manualmente. Guarda 2 ó 3 segundos de la secuencia detectada en un archivo de vídeo. Muestra el objeto seleccionado anulando el fondo. Impleméntalo de dos maneras: a) Utilizando un substractor de fondo de opencv como en los ejemplos backsub0.py y backsub.py. b) Mediante un procedimiento sencillo que construya un modelo de fondo con frames anteriores y compare con el actual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COLOR**. Construye un contador de objetos que tengan un color característico en la escena, simplemente pinchando con el ratón en dos o tres de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FILTROS**. Amplía el código de la práctica 4 para mostrar en vivo el efecto de diferentes filtros, seleccionando con el teclado el filtro deseado y modificando sus parámetros (p.ej. el nivel de suavizado) con trackbars. Aplica el filtro en un ROI para comparar el resultado con el resto de la imagen ([ejemplo](../images/demos/ej-c4.png)). Opcional: **a)** Comprueba la propiedad de \"cascading\" del filtro gaussiano. **b)** Comprueba la propiedad de \"separabilidad\" del filtro gaussiano. **c)** Implementa en Python dede cero (usando bucles) el algoritmo de convolución con una máscara general y compara su eficiencia con la versión de OpenCV. **c)** Impleméntalo en C y haz un \"wrapper\" para utilizarlo desde Python (consulta al profesor). **d)** Implementa el box filter con la imagen integral. **e)** Añade la posibilidad de seleccionar varios filtros para aplicarlos sucesivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT**. Escribe una aplicación de reconocimiento de objetos (p. ej. carátulas de CD, portadas de libros, cuadros de pintores, etc.) con la webcam basada en el número de coincidencias de *keypoints*. [Más información](FAQ.ipynb#Ejercicio-SIFT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECTIF**. Rectifica la imagen de un plano para medir distancias (tomando manualmente referencias conocidas). Por ejemplo, mide la distancia entre las monedas en `coins.png` o la distancia a la que se realiza el disparo en `gol-eder.png`. Las coordenadas reales de los puntos de referencia y sus posiciones en la imagen deben pasarse como parámetro en un archivo de texto. Aunque puedes mostrar la imagen rectificada para comprobar las operaciones, debes marcar los puntos y mostrar el resultado sobre la imagen original. Verifica los resultados con **imágenes originales** tomadas por ti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RA**. Crea un efecto de realidad aumentada en el que el usuario interactúe con los objetos virtuales. Por ejemplo, haciendo que un objeto se desplace hacia un punto señalado con el ratón."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opcionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DELOGO**. Detecta el logotipo (y otros elementos fijos) de una cadena de TV en una emisión por streaming y a) elimínalo, b) suprime los cortes publicitarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VROT**. Amplía el *tracker* de Lucas-Kanade (ejemplo `LK/lk_track.py`) para **a)** determinar en qué dirección se mueve la cámara (UP,DOWN,LEFT,RIGHT, [FORWARD, BACKWARD]); **b)** estimar de forma aproximada la velocidad angular de rotación de la cámara (grados/segundo). [Más información](FAQ.ipynb#Ejercicio-VROT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SILU**. Amplía el reconocedor de siluetas para que admita múltiples prototipos. Intenta leer placas de matrícula vistas de frente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CR**. Reproduce la demostración del cross-ratio de 4 puntos en una recta del tema de [transformaciones del plano](transf2D.ipynb#Invariantes). Marca tres puntos con el ratón y añade automáticamente tres más y el punto de fuga, suponiendo que en el mundo real los puntos están alineados y a la misma distancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SWAP**. Intercambia dos cuadriláteros en una escena marcando manualmente los puntos de referencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PANO**. Crea automáticamente un mosaico a partir de las imágenes en una carpeta. Las imágenes no tienen por qué estar ordenadas ni formar una cadena lineal y no sabemos el espacio que ocupa el resultado. El usuario debe intervenir lo menos posible. Recuerda que debe tratarse de una escena plana o de una escena cualquiera vista desde el mismo centro de proyección. Debes usar homografías. Compara el resultado con el que obtiene la utilidad de stitching de OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUDOKU**. Haz un programa capaz de rellenar con realidad aumentada un sudoku que se observa en una imagen en vivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARD**. Sustituye la foto de tu carnet de la UMU que se observa en una imagen en vivo. Intenta conseguir un resultado [parecido a esto](../images/demos/dni.mp4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LIBRE**. Resuelve un problema de visión artificial de tu elección. Se valorará la originalidad y la sencillez de la solución propuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Obligatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CALIBRACIÓN**. a) Realiza una calibración precisa de tu cámara mediante múltiples imágenes de un *chessboard*. b) Haz una calibración aproximada con un objeto de tamaño conocido y compara con el resultado anterior. c) Determina a qué altura hay que poner la cámara para obtener una vista cenital completa de un campo de baloncesto. d) Haz una aplicación para medir el ángulo que definen dos puntos marcados con el ratón en el imagen. e) Opcional: determina la posición aproximada desde la que se ha tomado una foto a partir ángulos observados respecto a puntos de referencia conocidos. [Más informacion](imagen.ipynb#Calibración)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ACTIVIDAD**. Construye un detector de movimiento en una región de interés de la imagen marcada manualmente. Guarda 2 ó 3 segundos de la secuencia detectada en un archivo de vídeo. Opcional: muestra el objeto seleccionado anulando el fondo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COLOR**. Construye un clasificador de objetos en base a la similitud de los histogramas de color del ROI (de los 3 canales por separado). [Más información](FAQ.ipynb#Ejercicio-COLOR). Opcional: Segmentación densa por reproyección de histograma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT**. Escribe una aplicación de reconocimiento de objetos (p. ej. carátulas de CD, portadas de libros, cuadros de pintores, etc.) con la webcam basada en el número de coincidencias de *keypoints*. [Más información](FAQ.ipynb#Ejercicio-SIFT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECTIF**. Rectifica la imagen de un plano para medir distancias (tomando manualmente referencias conocidas). Por ejemplo, mide la distancia entre las monedas en `coins.png` o la distancia a la que se realiza el disparo en `gol-eder.png`. Las coordenadas reales de los puntos de referencia y sus posiciones en la imagen deben pasarse como parámetro en un archivo de texto. Aunque puedes mostrar la imagen rectificada para comprobar las operaciones, debes marcar los puntos y mostrar el resultado sobre la imagen original. Verifica los resultados con **imágenes originales** tomadas por ti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RA**. Crea un efecto de realidad aumentada **interactivo**: esto significa que a) los objetos virtuales deben cambiar de forma, posición o tamaño siguiendo alguna lógica; b) el usuario puede observar la escena cambiante desde cualquier punto de vista moviendo la cámara alrededor del marcador; y c) el usuario puede marcar con el ratón en la imagen puntos del plano de la escena para interactuar con los objetos virtuales. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Opcionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FILTROS**. Amplía el código de la práctica 4 para mostrar en vivo el efecto de diferentes filtros, seleccionando con el teclado el filtro deseado y modificando sus parámetros (p.ej. el nivel de suavizado) con trackbars. **a)** Aplica el filtro en un ROI para comparar el resultado con el resto de la imagen ([ejemplo](../images/demos/ej-c4.png)). **b)** Comprueba la propiedad de \"cascading\" del filtro gaussiano. **c)** Comprueba la propiedad de \"separabilidad\" del filtro gaussiano. **d)** Implementa en Python dede cero (usando bucles) el algoritmo de convolución con una máscara general y compara su eficiencia con la versión de OpenCV. **e)** Impleméntalo en C y haz un wrapper para utilizarlo desde Python (consulta al profesor). **f)** Implementa el box filter con la imagen integral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VROT**. Amplía el *tracker* de Lucas-Kanade (ejemplo `LK/lk_track.py`) para **a)** determinar en qué dirección se mueve la cámara (UP,DOWN,LEFT,RIGHT, [FORWARD, BACKWARD]); **b)** estimar de forma aproximada la velocidad angular de rotación de la cámara (grados/segundo). [Más información](FAQ.ipynb#Ejercicio-VROT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DELOGO**. Detecta el logotipo de una cadena de TV en una emisión por streaming y suprime los cortes publicitarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SILU**. Amplía el reconocedor de siluetas para que admita múltiples prototipos y compara la capacidad de discriminación de los descriptores frecuenciales con los basados en los invariantes de Hu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CR**. Reproduce la demostración del cross-ratio de 4 puntos en una recta del tema de [transformaciones del plano](transf2D.ipynb#Invariantes). Marca tres puntos con el ratón y añade automáticamente tres más y el punto de fuga, suponiendo que en el mundo real los puntos están alineados y a la misma distancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SWAP**. Intercambia dos cuadriláteros en una escena marcando manualmente los puntos de referencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARD**. Sustituye la foto de tu carnet de la UMU que se observa en una imagen en vivo. Intenta conseguir un resultado [parecido a esto](../images/demos/dni.mp4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PANO**. Crea automáticamente un mosaico a partir de las imágenes en una carpeta. Las imágenes no tienen por qué estar ordenadas ni formar una cadena lineal y no sabemos el espacio que ocupa el resultado. El usuario debe intervenir lo menos posible. Recuerda que debe tratarse de una escena plana o de una escena cualquiera vista desde el mismo centro de proyección. Debes usar homografías. Compara el resultado con el que obtiene la utilidad de stitching de OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUDOKU**. Haz un programa capaz de rellenar con realidad aumentada un sudoku que se observa en una imagen en vivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LIBRE**. Resuelve un problema de visión artificial de tu elección. Se valorará la originalidad y la sencillez de la solución propuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Obligatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CALIBRACIÓN**. a) Realiza una calibración precisa de tu cámara mediante múltiples imágenes de un *chessboard*. b) Haz una calibración aproximada con un objeto de tamaño conocido y compara con el resultado anterior. c) Determina a qué altura hayu que poner la cámara para obtener una vista cenital completa de un campo de baloncesto. d) Haz una aplicación para medir el ángulo que definen dos puntos marcados con el ratón en el imagen. e) Opcional: determina la posición aproximada desde la que se ha tomado una foto a partir ángulos observados respecto a puntos de referencia conocidos. [Más informacion](imagen.ipynb#Calibración)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ACTIVIDAD**. Construye un detector de movimiento en una región de interés de la imagen marcada manualmente. Guarda 2 ó 3 segundos de la secuencia detectada en un archivo de vídeo. Opcional: muestra el objeto seleccionado anulando el fondo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COLOR**. Construye un clasificador de objetos en base a la similitud de los histogramas de color del ROI (de los 3 canales por separado). [Más información](FAQ.ipynb#Ejercicio-COLOR). Opcional: Segmentación densa por reproyección de histograma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FILTROS**. Muestra el efecto de diferentes filtros sobre la imagen en vivo de la webcam. Selecciona con el teclado el filtro deseado y modifica sus posibles parámetros (p.ej. el nivel de suavizado) con las teclas o con trackbars. Aplica el filtro en un ROI para comparar el resultado con el resto de la imagen. Opcional: implementa en Python o C \"desde cero\" algún filtro y compara la eficiencia con OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT**. Escribe una aplicación de reconocimiento de objetos (p. ej. carátulas de CD, portadas de libros, cuadros de pintores, etc.) con la webcam basada en el número de coincidencias de *keypoints*. [Más información](FAQ.ipynb#Ejercicio-SIFT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECTIF**. Rectifica la imagen de un plano para medir distancias (tomando manualmente referencias conocidas). Por ejemplo, mide la distancia entre las monedas en `coins.png` o la distancia a la que se realiza el disparo en `gol-eder.png`. Verifica los resultados con imágenes originales tomadas por ti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PANO**. Crea automáticamente un mosaico a partir de las imágenes en una carpeta. Las imágenes no tienen por qué estar ordenadas ni formar una cadena lineal y no sabemos el espacio que ocupa el resultado. El usuario debe intervenir lo menos posible. Recuerda que debe tratarse de una escena plana o de una escena cualquiera vista desde el mismo centro de proyección. Debes usar homografías. Compara el resultado con el que obtiene la utilidad de stitching de OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RA**. Crea un efecto de realidad aumentada **interactivo**: esto significa que a) los objetos virtuales deben cambiar de forma, posición o tamaño siguiendo alguna lógica; b) el usuario puede observar la escena cambiante desde cualquier punto de vista moviendo la cámara alrededor del marcador; y c) el usuario puede marcar con el ratón en la imagen puntos del plano de la escena para interactuar con los objetos virtuales. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPT**. Un ejercicio a elegir entre los opcionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Opcionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DLIB**. Escribe una aplicación de tu invención que utilice los [marcadores de cara](https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/) obtenidos por el *shape detector* disponible en [dlib](http://dlib.net/) (ejemplo `/hog/facelandmarks.py`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VROT**. Estima de forma aproximada la velocidad angular de rotación de la cámara (grados/segundo) analizando las trayectorias obtenidas por el *tracker* de Lucas-Kanade (ejemplo `LK/lk_track.py`). [Más información](FAQ.ipynb#Ejercicio-VROT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DELOGO**. Detecta el logotipo de una cadena de TV en una emisión por streaming y suprime los cortes publicitarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SILU**. Escribe una aplicación de reconocimiento de siluetas con la webcam basado en descriptores frecuenciales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANON**. Modifica el ejemplo de reconocimiento de caras `DL/facerec` para seleccionar caras pinchando con el ratón (o tomándolas de un directorio) para que cuando se reconozcan en las imágenes se oculten (emborronándolas o pixelizándolas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CR**. Reproduce la demostración del cross-ratio de 4 puntos en una recta del tema de [transformaciones del plano](transf2D.ipynb#Invariantes). Marca tres puntos con el ratón y añade automáticamente tres más y el punto de fuga, suponiendo que en el mundo real los puntos están alineados y a la misma distancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SWAP**. Intercambia dos cuadriláteros en una escena marcando manualmente los puntos de referencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NFACE**. Implementa la normalización de caras explicada en la sección de [transformaciones afines](transf2D.ipynb#Transformaciones-afines)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DNI**. Sustituye la foto de un carnet que se observa en una imagen en vivo. Intenta conseguir un resultado [parecido a esto](../images/demos/dni.mp4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUDO**. Haz un programa capaz de rellenar un sudoku que se observa en una imagen en vivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STC**. Resuelve los problemas planteados en el notebook [stereo-challenge](stereo-challenge.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ORIG**. Resuelve un problema de tu elección."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

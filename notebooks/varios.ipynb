{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook comentamos brevemente algunas técnicas específicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de caras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método clásico ([Viola & Jones, 2001](https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework)) esta basado en [AdaBoost](https://en.wikipedia.org/wiki/AdaBoost), que es una técnica muy importante dentro de *Machine Learning* basada en la combinación de \"weak features\" para conseguir un clasificador de alta precisión. OpenCV incluye una buena implementación. Detecta la cara y dentro de ella otras zonas como los ojos, nariz, etc., como se muestra a continuación.\n",
    "\n",
    "Pero en la actualidad es más recomendable el detector de caras disponible en el paquete DLIB que hemos utilizado ya en el ejercicio de los *face landmarks*. Lo usaremos también en el capítulo de Deep Learning como apoyo para el reconocimiento de la identidad de la personas.\n",
    "\n",
    "Por su interés histórico mostramos aquí el uso de la implementación del método AdaBoost disponible en OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2   as cv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def readrgb(file):\n",
    "    return cv.cvtColor( cv.imread('../images/'+file), cv.COLOR_BGR2RGB) \n",
    "\n",
    "def rgb2gray(x):\n",
    "    return cv.cvtColor(x,cv.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intentamos encontrar automáticamente la ubicación de las cascadas (los clasificadores preentrenados)\n",
    "\n",
    "import site\n",
    "\n",
    "site_packages_paths = site.getsitepackages()\n",
    "print(site_packages_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpath = site_packages_paths[0]+\"/cv2/data/\"\n",
    "\n",
    "# Comprobamos que los dectectores se han cargado bien\n",
    "face_cascade = cv.CascadeClassifier(cpath+'/haarcascade_frontalface_default.xml')\n",
    "print(not face_cascade.empty())\n",
    "\n",
    "eye_cascade = cv.CascadeClassifier(cpath+'haarcascade_eye.xml')\n",
    "print(not eye_cascade.empty())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo probamos con algunas imágenes del repositorio. También es fácil ponerlo en marcha con la webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = readrgb('monty-python1.jpg')\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_cascade.detectMultiScale(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devuelve una colección de rectángulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = img.copy()\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv.rectangle(out,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "plt.imshow(out);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = readrgb('monty-python2.jpg')\n",
    "faces = face_cascade.detectMultiScale(img)\n",
    "print(faces)\n",
    "out = img.copy()\n",
    "for (x,y,w,h) in faces:\n",
    "    cv.rectangle(out,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "plt.imshow(out);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = readrgb('scarlett.jpg')\n",
    "faces = face_cascade.detectMultiScale(img)\n",
    "print(faces)\n",
    "out = img.copy()\n",
    "for (x,y,w,h) in faces:\n",
    "    cv.rectangle(out,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "plt.imshow(out);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de las caras detectamos los ojos con el \"eye_cascade\". (En la foto de Scarlett mi versión de opencv detecta 3 ojos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = img.copy()\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv.rectangle(out,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi = out[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv.rectangle(roi,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "plt.imshow(out);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ejercicio puedes comparar informalmente la precisión y el tiempo de cómputo de este detector y el disponible en DLIB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconocimiento óptico de caracteres (OCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El reconocimiento de caracteres impresos en imágenes de alta resolución escaneadas con buena calidad y sin ruido puede abordarse mediante una sencilla comparación con los modelos de cada letra. Pero en situaciones más realistas, donde hay ruido y menor resolución, es necesario un ataque más elaborado. El problema se complica aún más si en lugar de escanear el texto lo capturamos con una cámara.\n",
    "\n",
    "La imagen siguiente es un texto escaneado (hace tiempo) en modo binario:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/texto.png\" width=\"800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando ampliamos la imagen observamos que muchas letras son componentes conexas independientes, que en principio pueden reconocerse fácilmente. Pero también hay algunos casos de letras unidas, como la secuencia \"arru\", en la que la comparación de las manchas con los modelos requiere partirla correctamente en trozos. Esto da lugar a una combinatoria que finalmente solo se puede resolver de forma probabilística y con un diccionario de palabras válidas. Si la intensidad de la tinta es pequeña, algunas letras pueden aparecer divididas en varias componentes conexas, lo cual aumenta aún más la combinatoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/demos/texto-detalle.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede abordar el desarrollo de un OCR sencillo como práctica opcional. Si estás interesado consulta con el profesor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen muchos OCR comerciales. Dentro de las soluciones de software libre destacamos el paquete [tesseract](https://github.com/tesseract-ocr). Dispone de un ejecutable y de una biblioteca que se puede utilizar por programa desde Python y otros lenguajes.\n",
    "\n",
    "Veamos el resultado que consigue el ejecutable con el texto de prueba anterior (disponible en el repositorio).\n",
    "\n",
    "\n",
    "**> tesseract texto.png resul**\n",
    "    \n",
    "<pre>Quizé sea éste uno de los articulos més ilusos que uno pueda escribir\n",
    "hoy en d1’a en una socicdad tan autocomplaciente y autoindulgente\n",
    "como la espaﬁola actual, y eso que tengo conciencia de haber ya\n",
    "publicado unos cuantos dc esa indole —i1usa, quiero decir-. Porque si\n",
    "para algo no estzi la superﬁcialidad ambiente es para atender, a estas\n",
    "alturas, a asuntos que ni siquiera sé cémo caliﬁcar si no es con\n",
    "anticuadas palabras, casi arrumbadas; y desde luego no deseo recurrir a\n",
    "la ya vacua -por estrujada- \"ética\": Lasuntos que ataﬁen a la rectitud?\n",
    "g,A1o venial y a lo grave? g,A1as conductas? (,A1a dignidad? Si, todo\n",
    "suena ya trasnochado.</pre>\n",
    "\n",
    "Se producen muchos errores porque no hemos indicado el idioma. Cuando lo hacemos el resultado es prácticamente perfecto:\n",
    "\n",
    "**> tesseract texto.png resul -l spa**\n",
    "\n",
    "\n",
    "<pre>Quizá sea éste uno de los artículos más ilusos que uno pueda escribir\n",
    "hoy en día en una sociedad tan autocomplaciente y autoindulgente\n",
    "como la española actual, y eso que tengo conciencia de haber ya\n",
    "publicado unos cuantos de esa índole —ilusa, quiero decir-. Porque si\n",
    "para algo no está la superﬁcialidad ambiente es para atender, a estas\n",
    "alturas, a asuntos que ni siquiera sé cómo caliﬁcar si no es con\n",
    "anticuadas palabras, casi arrumbadas; y desde luego no deseo recurrir a\n",
    "la ya vacua -por estrujada- \"ética\": ¿asuntos que atañen ala rectitud?\n",
    "¿A lo venial y a lo grave? ¿A las conductas? ¿Ala dignidad? Sí, todo\n",
    "suena ya trasnochado.</pre>\n",
    "\n",
    "Curiosamente, introduce [ligaduras](https://en.wikipedia.org/wiki/Orthographic_ligature): super<b>ﬁ</b>cialidad, cali<b>ﬁ</b>car, y como no entiende el significado ha juntado \"a la\" en \"ala\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El motor computacional de tesseract se puede utilizar en programas de Python mediante diversos paquetes que proporcionan interfaces más o menos cómodos. Uno muy conocido es `pytesseract`, pero tiene el inconveniente de que en realidad hace simples llamadas al ejecutable a través de archivos intermedios. Esto es muy lento si se hacen llamadas sucesivas en imágenes en vivo o en muchos recortes de una imagen.\n",
    "\n",
    "Mi recomendación es usar el paquete [tesserocr](https://pypi.org/project/tesserocr/). Proporciona el API de tesseract, de modo que se puede usar de forma mucho más eficiente. Se instala fácilmente con pip, pero necesita algún paquete del sistema:\n",
    "\n",
    "    sudo apt install tesseract-ocr  tesseract-ocr-spa libtesseract-dev libleptonica-dev pkg-config \n",
    "    pip install tesserocr\n",
    "\n",
    "En la sesión de prácticas veremos un código de ejemplo muy sencillo que muestra cómo utilizar este módulo en imágenes en vivo.\n",
    "\n",
    "![ocr1](../images/demos/ocr1.png)\n",
    "\n",
    "Tolera pequeñas rotaciones,\n",
    "\n",
    "![ocr2](../images/demos/ocr2.png)\n",
    "\n",
    "diferentes tipos de letra,\n",
    "\n",
    "![ocr3](../images/demos/ocr3.png)\n",
    "\n",
    "y desenfoque\n",
    "\n",
    "![ocr](../images/demos/ocr4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Códigos de barras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los códigos de barras, los códigos bidimensionales QR y otras variantes, como los códigos en color que vemos en las paradas del tranvía, son objetos artificiales diseñados expresamente para ser fácilmente distinguibles. En principio se podría abordar como ejercicio avanzado un prototipo de lector de códigos sencillos en condiciones favorables. Debido a las limitaciones de tiempo nos limitaremos a comentar el paquete de software libre [zbar](http://zbar.sourceforge.net/), que es capaz de leer varios tipos de códigos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que instalar el paquete del systema `libzbar-dev`.\n",
    "\n",
    "El ejecutable `zbarimg` admite ficheros de imagen:\n",
    "\n",
    "<img src=\"../images/demos/barcode.jpg\" width=\"400px\"/>\n",
    "\n",
    "<pre>$ zbarimg barcode.jpg \n",
    "EAN-13:9789813083714\n",
    "scanned 1 barcode symbols from 1 images in 0.35 seconds</pre>\n",
    "\n",
    "La utilidad `zbarcam` trabaja con imágenes en vivo de la webcam:\n",
    "\n",
    "\n",
    "<img src=\"../images/demos/barcode1.png\" width=\"500px\"/>\n",
    "\n",
    "<img src=\"../images/demos/barcode2.png\" width=\"500px\"/>\n",
    "\n",
    "<pre>$ zbarcam --prescale=640x480\n",
    "EAN-13:3134375261920\n",
    "EAN-13:9780201814149\n",
    "EAN-13:9780801854149\n",
    "EAN-13:3134375261920\n",
    "EAN-13:3134375261920\n",
    "EAN-13:9780801854149</pre>\n",
    "\n",
    "![image](../images/demos/barcode3.png)\n",
    "\n",
    "En los casos anteriores detecta el código y el estándard utilizado, en este caso [EAN-13](https://en.wikipedia.org/wiki/International_Article_Number). En esta último pantallazo detecta también un \"CODE-128\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QR codes\n",
    "\n",
    "También es capaz de leer códigos QR. En el pantallazo siguiente se muestra la decodificación del [código QR de ejemplo](../images/qrcode.png) disponible en el repositorio, que contiene como texto el comando de instalación del módulo umucv.\n",
    "\n",
    "![image](../images/demos/qrcode.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zbar in Python\n",
    "\n",
    "El motor de decodificación se puede utilizar fácilmente en Python a través del paquete `pyzbar`. En la sesión práctica veremos el ejemplo de código [zbardemo.py](../code/zbardemo.py) para decodificar los códigos que aparezcan en cualquier secuencia de imágenes.\n",
    "\n",
    "![barcode](../images/demos/barcode.png)\n",
    "\n",
    "En los QR obtenemos también las esquinas con precisión, muy útiles en algunas aplicaciones de geometría visual.\n",
    "\n",
    "![qr](../images/demos/qr2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GrabCut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de [cortes de grafos][graphcuts] tienen aplicación en [algunos problemas](https://en.wikipedia.org/wiki/Graph_cuts_in_computer_vision) de visión artificial.\n",
    "\n",
    "Por ejemplo, en segmentación de imágenes (distinguir objetos del fondo) se define un grafo donde los vértices son los pixels, se establecen arcos entre pixels vecinos con pesos que indican si son parecidos o no, y se busca el menor corte del grafo (eliminar arcos) que maximiza la separación entre el objeto y el fondo. Aquí tenemos un breve [tutorial][tutorial] de OpenCV. El código fuente está en el repositorio: [code/grabcut.py](../code/grabcut.py). Es un procedimiento interactivo que comentaremos en una sesión de prácticas.\n",
    "\n",
    "[graphcuts]: https://en.wikipedia.org/wiki/Cut_(graph_theory)\n",
    "\n",
    "[tutorial]: https://docs.opencv.org/3.4/d8/d83/tutorial_py_grabcut.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de elipses\n",
    "\n",
    "Lo explicaremos en detalle en una sesión de prácticas."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
